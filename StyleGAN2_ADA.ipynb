{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleGAN2 ADA",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "komy8UA_ynRj",
        "outputId": "937ea42f-cfc3-44f4-a5c2-9986722d3027"
      },
      "source": [
        "!unzip Cats.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Cats.zip\n",
            "  inflating: Cats/Cats1.jpg          \n",
            "  inflating: Cats/Cats10.jpg         \n",
            "  inflating: Cats/Cats11.jpg         \n",
            "  inflating: Cats/Cats12.jpg         \n",
            "  inflating: Cats/Cats13.jpg         \n",
            "  inflating: Cats/Cats14.jpg         \n",
            "  inflating: Cats/Cats15.jpg         \n",
            "  inflating: Cats/Cats16.jpg         \n",
            "  inflating: Cats/Cats17.jpg         \n",
            "  inflating: Cats/Cats18.jpg         \n",
            "  inflating: Cats/Cats19.jpg         \n",
            "  inflating: Cats/Cats2.jpg          \n",
            "  inflating: Cats/Cats20.jpg         \n",
            "  inflating: Cats/Cats21.jpg         \n",
            "  inflating: Cats/Cats22.jpg         \n",
            "  inflating: Cats/Cats23.jpg         \n",
            "  inflating: Cats/Cats24.jpg         \n",
            "  inflating: Cats/Cats25.jpg         \n",
            "  inflating: Cats/Cats26.jpg         \n",
            "  inflating: Cats/Cats27.jpg         \n",
            "  inflating: Cats/Cats28.jpg         \n",
            "  inflating: Cats/Cats29.jpg         \n",
            "  inflating: Cats/Cats3.jpg          \n",
            "  inflating: Cats/Cats30.jpg         \n",
            "  inflating: Cats/Cats31.jpg         \n",
            "  inflating: Cats/Cats32.jpg         \n",
            "  inflating: Cats/Cats33.jpg         \n",
            "  inflating: Cats/Cats34.jpg         \n",
            "  inflating: Cats/Cats35.jpg         \n",
            "  inflating: Cats/Cats36.jpg         \n",
            "  inflating: Cats/Cats37.jpg         \n",
            "  inflating: Cats/Cats38.jpg         \n",
            "  inflating: Cats/Cats39.jpg         \n",
            "  inflating: Cats/Cats4.jpg          \n",
            "  inflating: Cats/Cats40.jpg         \n",
            "  inflating: Cats/Cats41.jpg         \n",
            "  inflating: Cats/Cats42.jpg         \n",
            "  inflating: Cats/Cats43.jpg         \n",
            "  inflating: Cats/Cats44.jpg         \n",
            "  inflating: Cats/Cats45.jpg         \n",
            "  inflating: Cats/Cats46.jpg         \n",
            "  inflating: Cats/Cats47.jpg         \n",
            "  inflating: Cats/Cats48.jpg         \n",
            "  inflating: Cats/Cats49.jpg         \n",
            "  inflating: Cats/Cats5.jpg          \n",
            "  inflating: Cats/Cats50.jpg         \n",
            "  inflating: Cats/Cats51.jpg         \n",
            "  inflating: Cats/Cats52.jpg         \n",
            "  inflating: Cats/Cats53.jpg         \n",
            "  inflating: Cats/Cats54.jpg         \n",
            "  inflating: Cats/Cats55.jpg         \n",
            "  inflating: Cats/Cats56.jpg         \n",
            "  inflating: Cats/Cats57.jpg         \n",
            "  inflating: Cats/Cats58.jpg         \n",
            "  inflating: Cats/Cats59.jpg         \n",
            "  inflating: Cats/Cats6.jpg          \n",
            "  inflating: Cats/Cats60.jpg         \n",
            "  inflating: Cats/Cats61.jpg         \n",
            "  inflating: Cats/Cats62.jpg         \n",
            "  inflating: Cats/Cats63.jpg         \n",
            "  inflating: Cats/Cats64.jpg         \n",
            "  inflating: Cats/Cats65.jpg         \n",
            "  inflating: Cats/Cats66.jpg         \n",
            "  inflating: Cats/Cats67.jpg         \n",
            "  inflating: Cats/Cats68.jpg         \n",
            "  inflating: Cats/Cats69.jpg         \n",
            "  inflating: Cats/Cats7.jpg          \n",
            "  inflating: Cats/Cats70.jpg         \n",
            "  inflating: Cats/Cats71.jpg         \n",
            "  inflating: Cats/Cats72.jpg         \n",
            "  inflating: Cats/Cats73.jpg         \n",
            "  inflating: Cats/Cats74.jpg         \n",
            "  inflating: Cats/Cats75.jpg         \n",
            "  inflating: Cats/Cats76.jpg         \n",
            "  inflating: Cats/Cats77.jpg         \n",
            "  inflating: Cats/Cats78.jpg         \n",
            "  inflating: Cats/Cats79.jpg         \n",
            "  inflating: Cats/Cats8.jpg          \n",
            "  inflating: Cats/Cats80.jpg         \n",
            "  inflating: Cats/Cats9.jpg          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE3j8Ccjy780",
        "outputId": "4c963497-2f71-438f-80ad-3aafb13dd0d3"
      },
      "source": [
        "!git clone https://github.com/NVlabs/stylegan2-ada.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylegan2-ada'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 74 (delta 0), reused 1 (delta 0), pack-reused 71\u001b[K\n",
            "Unpacking objects: 100% (74/74), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88_GEXDWzPmJ",
        "outputId": "aac42bad-8f5f-4150-c145-01524462fdb2"
      },
      "source": [
        "!dir"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cats  Cats.zip\tsample_data  stylegan2-ada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg8CcKIJzS45",
        "outputId": "558eba42-4cc3-47fc-c956-d7d3eda39e5c"
      },
      "source": [
        "cd stylegan2-ada"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stylegan2-ada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMwTKMiozVlh",
        "outputId": "cf4eef76-a7a0-426c-e358-0bb1b02aa8f6"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "path = '/content/Cats/'\n",
        "im_size = 256   \n",
        "images = []\n",
        "\n",
        "for file in os.listdir(path):\n",
        "        img = cv2.imread(path + '/' + file)  \n",
        "        img = cv2.resize(img, (im_size, im_size))\n",
        "        print(img.shape)\n",
        "        images.append(img)\n",
        "        cv2.imwrite('/content/resized_dataset/' + str(file) + '_resized.jpg', img)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(256, 256, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUcbboOs1BZR",
        "outputId": "c07aec6e-c93c-4525-df53-fb488839507b"
      },
      "source": [
        "!pip install tensorflow==1.14"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==1.14\n",
            "  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3 MB 44 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.42.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "\u001b[K     |████████████████████████████████| 488 kB 39.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.13.3)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 16.1 MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.4.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.19.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.37.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (3.17.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.10.0.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14) (1.5.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.6 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnPvihIR0k7Z",
        "outputId": "4d5f4476-2e71-45ab-8e2f-e6f4cba12ab0"
      },
      "source": [
        "!pip install tqdm\n",
        "\n",
        "!python dataset_tool.py create_from_images /content/tfrecords_dataset/ /content/Cats/"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Loading images from \"/content/Cats/\"\n",
            "Creating dataset \"/content/tfrecords_dataset/\"\n",
            "dataset_tool.py:96: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
            "  'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[quant.tostring()]))}))\n",
            "Added 80 images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjLr2Q4R01sU",
        "outputId": "42179c84-6f9b-4983-e3f5-14e9584de3fb"
      },
      "source": [
        "!python train.py --outdir ./results --snap=10 --data=/content/tfrecords_dataset --augpipe=bgcfnc --res=256"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x557a08afe000 @  0x7fda4bdf3001 0x7fda4903654f 0x7fda49086b58 0x7fda4908ab17 0x7fda49129203 0x557a01d94544 0x557a01d94240 0x557a01e08627 0x557a01e02ced 0x557a01d9648c 0x557a01dd7159 0x557a01dd40a4 0x557a01d94d49 0x557a01e0894f 0x557a01e029ee 0x557a01cd4e2b 0x557a01e04fe4 0x557a01e029ee 0x557a01cd4e2b 0x557a01e04fe4 0x557a01e02ced 0x557a01cd4e2b 0x557a01e04fe4 0x557a01d95afa 0x557a01e03915 0x557a01e029ee 0x557a01e026f3 0x557a01ecc4c2 0x557a01ecc83d 0x557a01ecc6e6 0x557a01ea4163\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x557b08afe000 @  0x7fda4bdf11e7 0x7fda4903646e 0x7fda49086c7b 0x7fda4908735f 0x7fda49129103 0x557a01d94544 0x557a01d94240 0x557a01e08627 0x557a01e029ee 0x557a01d95bda 0x557a01e04737 0x557a01e029ee 0x557a01d95bda 0x557a01e04737 0x557a01e029ee 0x557a01d95bda 0x557a01e04737 0x557a01d95afa 0x557a01e03915 0x557a01e029ee 0x557a01d95bda 0x557a01e07d00 0x557a01e029ee 0x557a01d95bda 0x557a01e04737 0x557a01e02ced 0x557a01d9648c 0x557a01dd7159 0x557a01dd40a4 0x557a01d94d49 0x557a01e0894f\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x557c09306000 @  0x7fda4bdf11e7 0x7fda4903646e 0x7fda49086c7b 0x7fda4908735f 0x7fda3225d3f7 0x7fda320a4d92 0x7fda320a5352 0x7fda32063baa 0x557a01d94437 0x557a01d94240 0x557a01e080f3 0x557a01d95afa 0x557a01e03c0d 0x557a01e02ced 0x557a01cd4eb0 0x557a01e04fe4 0x557a01e029ee 0x557a01d95bda 0x557a01e03c0d 0x557a01e02ced 0x557a01d95bda 0x557a01e03c0d 0x557a01d95afa 0x557a01e03c0d 0x557a01e029ee 0x557a01d96271 0x557a01d96698 0x557a01e04fe4 0x557a01e029ee 0x557a01d95bda 0x557a01e03915\n",
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_args\": {\n",
            "    \"func_name\": \"training.networks.G_main\",\n",
            "    \"fmap_base\": 8192,\n",
            "    \"fmap_max\": 512,\n",
            "    \"mapping_layers\": 2,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"D_args\": {\n",
            "    \"func_name\": \"training.networks.D_main\",\n",
            "    \"mbstd_group_size\": 4,\n",
            "    \"fmap_base\": 8192,\n",
            "    \"fmap_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_args\": {\n",
            "    \"beta1\": 0.0,\n",
            "    \"beta2\": 0.99,\n",
            "    \"learning_rate\": 0.0025\n",
            "  },\n",
            "  \"D_opt_args\": {\n",
            "    \"beta1\": 0.0,\n",
            "    \"beta2\": 0.99,\n",
            "    \"learning_rate\": 0.0025\n",
            "  },\n",
            "  \"loss_args\": {\n",
            "    \"func_name\": \"training.loss.stylegan2\",\n",
            "    \"r1_gamma\": 0.8192\n",
            "  },\n",
            "  \"augment_args\": {\n",
            "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
            "    \"tune_heuristic\": \"rt\",\n",
            "    \"tune_target\": 0.6,\n",
            "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
            "    \"apply_args\": {\n",
            "      \"xflip\": 1,\n",
            "      \"rotate90\": 1,\n",
            "      \"xint\": 1,\n",
            "      \"scale\": 1,\n",
            "      \"rotate\": 1,\n",
            "      \"aniso\": 1,\n",
            "      \"xfrac\": 1,\n",
            "      \"brightness\": 1,\n",
            "      \"contrast\": 1,\n",
            "      \"lumaflip\": 1,\n",
            "      \"hue\": 1,\n",
            "      \"saturation\": 1,\n",
            "      \"imgfilter\": 1,\n",
            "      \"noise\": 1,\n",
            "      \"cutout\": 1\n",
            "    }\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 10,\n",
            "  \"network_snapshot_ticks\": 10,\n",
            "  \"train_dataset_args\": {\n",
            "    \"path\": \"/content/tfrecords_dataset\",\n",
            "    \"max_label_size\": 0,\n",
            "    \"resolution\": 256,\n",
            "    \"mirror_augment\": false\n",
            "  },\n",
            "  \"metric_arg_list\": [\n",
            "    {\n",
            "      \"name\": \"fid50k_full\",\n",
            "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
            "      \"max_reals\": null,\n",
            "      \"num_fakes\": 50000,\n",
            "      \"minibatch_per_gpu\": 8,\n",
            "      \"force_dataset_args\": {\n",
            "        \"shuffle\": false,\n",
            "        \"max_images\": null,\n",
            "        \"repeat\": false,\n",
            "        \"mirror_augment\": false\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"metric_dataset_args\": {\n",
            "    \"path\": \"/content/tfrecords_dataset\",\n",
            "    \"max_label_size\": 0,\n",
            "    \"resolution\": 256,\n",
            "    \"mirror_augment\": false\n",
            "  },\n",
            "  \"total_kimg\": 25000,\n",
            "  \"minibatch_size\": 16,\n",
            "  \"minibatch_gpu\": 16,\n",
            "  \"G_smoothing_kimg\": 5.0,\n",
            "  \"G_smoothing_rampup\": 0.05,\n",
            "  \"run_dir\": \"./results/00000-tfrecords_dataset-res256-auto1-bgcfnc\"\n",
            "}\n",
            "\n",
            "Output directory:  ./results/00000-tfrecords_dataset-res256-auto1-bgcfnc\n",
            "Training data:     /content/tfrecords_dataset\n",
            "Training length:   25000 kimg\n",
            "Resolution:        256\n",
            "Number of GPUs:    1\n",
            "\n",
            "Creating output directory...\n",
            "Loading training set...\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x557a08afe000 @  0x7fda4bdf3001 0x7fda4903654f 0x7fda49086b58 0x7fda4908ab17 0x7fda49129203 0x557a01d94544 0x557a01d94240 0x557a01e08627 0x557a01e02ced 0x557a01d9648c 0x557a01dd7159 0x557a01dd40a4 0x557a01d94d49 0x557a01e0894f 0x557a01e029ee 0x557a01cd4e2b 0x557a01e04fe4 0x557a01e029ee 0x557a01cd4e2b 0x557a01e04fe4 0x557a01e02ced 0x557a01cd4e2b 0x557a01e04fe4 0x557a01d95afa 0x557a01e03915 0x557a01e029ee 0x557a01e026f3 0x557a01ecc4c2 0x557a01ecc83d 0x557a01ecc6e6 0x557a01ea4163\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x557d09306000 @  0x7fda4bdf11e7 0x7fda4903646e 0x7fda49086c7b 0x7fda4908735f 0x7fda49129103 0x557a01d94544 0x557a01d94240 0x557a01e08627 0x557a01e029ee 0x557a01d95bda 0x557a01e04737 0x557a01e029ee 0x557a01d95bda 0x557a01e04737 0x557a01e029ee 0x557a01d95bda 0x557a01e04737 0x557a01d95afa 0x557a01e03915 0x557a01e029ee 0x557a01d95bda 0x557a01e07d00 0x557a01e029ee 0x557a01d95bda 0x557a01e04737 0x557a01e02ced 0x557a01d9648c 0x557a01dd7159 0x557a01dd40a4 0x557a01d94d49 0x557a01e0894f\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x557d09306000 @  0x7fda4bdf11e7 0x7fda4903646e 0x7fda49086c7b 0x7fda4908735f 0x7fda3225d3f7 0x7fda320a4d92 0x7fda320a5352 0x7fda32063baa 0x557a01d94437 0x557a01d94240 0x557a01e080f3 0x557a01d95afa 0x557a01e03c0d 0x557a01e02ced 0x557a01cd4eb0 0x557a01e04fe4 0x557a01e029ee 0x557a01d95bda 0x557a01e03c0d 0x557a01e02ced 0x557a01d95bda 0x557a01e03c0d 0x557a01d95afa 0x557a01e03c0d 0x557a01e029ee 0x557a01d96271 0x557a01d96698 0x557a01e04fe4 0x557a01e029ee 0x557a01d95bda 0x557a01e03915\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Failed!\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 561, in <module>\n",
            "    main()\n",
            "  File \"train.py\", line 553, in main\n",
            "    run_training(**vars(args))\n",
            "  File \"train.py\", line 451, in run_training\n",
            "    training_loop.training_loop(**training_options)\n",
            "  File \"/content/stylegan2-ada/training/training_loop.py\", line 123, in training_loop\n",
            "    Gs = G.clone('Gs')\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/network.py\", line 457, in clone\n",
            "    net.copy_vars_from(self)\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/network.py\", line 490, in copy_vars_from\n",
            "    src_net._get_vars()\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/network.py\", line 297, in _get_vars\n",
            "    self._vars = OrderedDict(self._get_own_vars())\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/network.py\", line 286, in _get_own_vars\n",
            "    self._init_graph()\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/network.py\", line 151, in _init_graph\n",
            "    out_expr = self._build_func(*self._input_templates, **build_kwargs)\n",
            "  File \"/content/stylegan2-ada/training/networks.py\", line 231, in G_main\n",
            "    num_layers = components.synthesis.input_shape[1]\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/network.py\", line 232, in input_shape\n",
            "    return self.input_shapes[0]\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/network.py\", line 219, in input_shapes\n",
            "    self._input_shapes = [t.shape.as_list() for t in self.input_templates]\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/network.py\", line 267, in input_templates\n",
            "    self._init_graph()\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/network.py\", line 151, in _init_graph\n",
            "    out_expr = self._build_func(*self._input_templates, **build_kwargs)\n",
            "  File \"/content/stylegan2-ada/training/networks.py\", line 439, in G_synthesis\n",
            "    x = layer(x, layer_idx=0, fmaps=nf(1), kernel=3)\n",
            "  File \"/content/stylegan2-ada/training/networks.py\", line 392, in layer\n",
            "    x = modulated_conv2d_layer(x, dlatents_in[:, layer_idx], fmaps=fmaps, kernel=kernel, up=up, resample_kernel=resample_kernel, fused_modconv=fused_modconv)\n",
            "  File \"/content/stylegan2-ada/training/networks.py\", line 105, in modulated_conv2d_layer\n",
            "    s = apply_bias_act(s, bias_var='mod_bias', trainable=trainable) + 1 # [BI] Add bias (initially 1).\n",
            "  File \"/content/stylegan2-ada/training/networks.py\", line 50, in apply_bias_act\n",
            "    return fused_bias_act(x, b=tf.cast(b, x.dtype), act=act, gain=gain, clamp=clamp)\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/ops/fused_bias_act.py\", line 72, in fused_bias_act\n",
            "    return impl_dict[impl](x=x, b=b, axis=axis, act=act, alpha=alpha, gain=gain, clamp=clamp)\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/ops/fused_bias_act.py\", line 132, in _fused_bias_act_cuda\n",
            "    cuda_op = _get_plugin().fused_bias_act\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/ops/fused_bias_act.py\", line 18, in _get_plugin\n",
            "    return custom_ops.get_plugin(os.path.splitext(__file__)[0] + '.cu')\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/custom_ops.py\", line 139, in get_plugin\n",
            "    compile_opts += f' --gpu-architecture={_get_cuda_gpu_arch_string()}'\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/custom_ops.py\", line 60, in _get_cuda_gpu_arch_string\n",
            "    raise RuntimeError('No GPU devices found')\n",
            "RuntimeError: No GPU devices found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZhcTmr42vRC"
      },
      "source": [
        "As you can see I am running out of GPUs. StyleGAN2 needs a lot of computational power."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELOebeSH31Ql",
        "outputId": "64ebd4d3-3db1-4e9d-b0c0-3522d441e824"
      },
      "source": [
        "# Using Pre-trained Weights\n",
        "!python generate.py --outdir=output1 --trunc=1 --seeds=0-10 --class=1 --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/cifar10.pkl"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Loading networks from \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/cifar10.pkl\"...\n",
            "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/cifar10.pkl ... done\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Failed!\n",
            "Traceback (most recent call last):\n",
            "  File \"generate.py\", line 121, in <module>\n",
            "    main()\n",
            "  File \"generate.py\", line 116, in main\n",
            "    generate_images(**vars(args))\n",
            "  File \"generate.py\", line 52, in generate_images\n",
            "    noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/network.py\", line 293, in vars\n",
            "    return copy.copy(self._get_vars())\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/network.py\", line 297, in _get_vars\n",
            "    self._vars = OrderedDict(self._get_own_vars())\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/network.py\", line 286, in _get_own_vars\n",
            "    self._init_graph()\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/network.py\", line 151, in _init_graph\n",
            "    out_expr = self._build_func(*self._input_templates, **build_kwargs)\n",
            "  File \"<string>\", line 431, in G_synthesis\n",
            "  File \"<string>\", line 384, in layer\n",
            "  File \"<string>\", line 97, in modulated_conv2d_layer\n",
            "  File \"<string>\", line 42, in apply_bias_act\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/ops/fused_bias_act.py\", line 72, in fused_bias_act\n",
            "    return impl_dict[impl](x=x, b=b, axis=axis, act=act, alpha=alpha, gain=gain, clamp=clamp)\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/ops/fused_bias_act.py\", line 132, in _fused_bias_act_cuda\n",
            "    cuda_op = _get_plugin().fused_bias_act\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/ops/fused_bias_act.py\", line 18, in _get_plugin\n",
            "    return custom_ops.get_plugin(os.path.splitext(__file__)[0] + '.cu')\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/custom_ops.py\", line 139, in get_plugin\n",
            "    compile_opts += f' --gpu-architecture={_get_cuda_gpu_arch_string()}'\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/custom_ops.py\", line 60, in _get_cuda_gpu_arch_string\n",
            "    raise RuntimeError('No GPU devices found')\n",
            "RuntimeError: No GPU devices found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOcE5b263-DJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}